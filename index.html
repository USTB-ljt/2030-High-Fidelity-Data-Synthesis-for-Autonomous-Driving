<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>科技创新2030重大项目</title>
  <link rel="stylesheet" href="assets/style.css"/>
</head>
<body>
  <div class="container">
    <header>
      <h1>科技创新2030重大项目——人工智能基础模型支撑平台与测评技术</h1>
      <h2>课题五：面向自动驾驶场景的高真实感数据合成</h2>
      
      <!-- 顶部导航按钮 -->
      <nav class="nav-buttons">
        <a href="pku.html">北京大学</a>
        <a href="chewang.html">车网科技</a>
        <a href="ustb.html">北京科技大学</a>
        <a href="ustc.html">中国科学技术大学</a>
        <a href="nankai.html">南开大学</a>
        <a href="wanwu.html">万物镜像</a>
      </nav>      
    </header>

  <div class="container">
    <!-- <header>
      <h1>科技创新2030重大项目——人工智能基础模型支撑平台与测评技术</h1>
      <h2>课题五：面向自动驾驶场景的高真实感数据合成</h2>
    </header>
    <hr/> -->

    <section>
      <h2>课题简介</h2>
      <p>视觉研究正逐步迈入以视觉预训练基础模型为核心的发展阶段，而大模型的成功离不开高质量的大规模数据支持。相较于语言模型，视觉数据存在自相关性弱、维度高、计算开销大、标注数据稀缺等问题，导致高质量数据供给难以持续，形成了明显的数据壁垒。智能驾驶作为人工智能算法与模型应用最为集中、需求最为迫切的领域之一，涵盖了众多复杂且具有挑战性的感知任务，亟需高质量视觉数据支撑。基于合成数据的视觉模型研究已成为当前的重要发展方向，借助智能驾驶场景库开展仿真数据合成，是破解自动驾驶研发瓶颈、加快技术落地的重要路径。本项目聚焦于面向自动驾驶场景的高真实感数据合成研究，致力于构建国际领先、服务于视觉模型应用落地的多模态高逼真度合成场景数据集，显著提升视觉预训练大模型在自动驾驶中的实际应用能力。项目基于自动驾驶示范园区中的典型真实场景，融合先进的真实感渲染技术，生成具备高精度、多模态标注的仿真数据集。通过将仿真数据与真实数据相融合开展模型训练，使模型能够同时利用标注完备的合成数据和未标注的真实数据，不断适应开放环境中动态变化的数据分布，逐步形成从仿真走向真实、从静态走向动态、从封闭走向开放环境的自适应学习能力。</p>
    </section>

    <hr/>
    <section>
      <h2>参研单位</h2>

      <h3>北京大学</h3>
      <p>课题承担单位，主要负责课题总体框架的构建，高真实感数据合成平台中的多模态传感器仿真、高真实感全局光照渲染系统以及高效物理仿真系统搭建，各领域课题研究成果的集成以及平台开发和维护等方面的工作。</p>
      <ul>
        <li>数据集: xxxx</li>
        <li>数据集: xxxx</li>
        <li>数据集: xxxx</li>
      </ul>

      <h3>北京车网科技发展有限公司</h3>
      <p>课题参与单位，主要负责高精度地图建设，数据采集系统部署和模型测试,推动平台在示范驾驶园区的对接与应用。</p>

      <h3>北京科技大学</h3>
      <p>课题参与单位，主要负责基于神经辐射场的场景生成研究，推动成果集成和算法应用。</p>
      <img src="images/pku_scene.png" alt="渲染系统结构" class="content-image" />
      <ul>
        <li><a href="www.baidu.com">驾驶场景图片数据集</a></li>
        <li><a href="www.baidu.com">多车辆驾驶场景合成数据集</a></li>
        <li><a href="www.baidu.com">Corner case交通事故场景真实数据集</a></li>
        <li><a href="www.baidu.com">Corner case交通事故场景合成数据集</a></li>
      </ul>
      <ul>
        <li><a href="www.baidu.com">基于NeRF-GAN的生成模型</a></li>
        <li><a href="www.baidu.com">基于Diffusion的生成模型</a></li>
      </ul>
      <ul>
        <li><a href="https://www.jcad.cn/">综述：自动驾驶仿真平台的现状与展望</a></li>
        <li><a href="https://yuyuyu223.github.io/homugan-projectpage/">论文：HomuGAN，TIP 2024</a></li>
        <img src="images/ustb/homugan.png" alt="基于NeRF的二维图像生成模型" class="content-image" />
        <li><a href="https://yuyuyu223.github.io/GET3DGS-projectpage/">论文：GET3DGS，TCSVT 2024</a></li>
        <img src="images/ustb/get3dgs.png" alt="基于3DGS的三维物体生成模型" class="content-image" />
      </ul>

      <h3>中国科学技术大学</h3>
      <p>课题参与单位，主要负责基于脉冲相机和Transformer研究高真实感场景合成、高精度场景仿真下模型训练问题，推动成果集成和模型训练。</p>

      <h3>南开大学</h3>
      <p>课题参与单位，主要负责高真实感数据合成平台中的真实感材质表达研究及全局光照算法技术突破,推动成果集成和数据协调。</p>

      <h3>万物镜像(北京)计算机系统有限公司</h3>
      <p>课题参与单位，主要负责高精度智能驾驶场景数字孪生资产构建，形成规范可共享开源数字资产，保障平台建设和应用，负责部分算法研发工作。</p>
    </section>
  </div>
</body>
</html>
